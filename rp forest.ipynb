{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def cos(vect1, vect2):\n",
    "    mag_vect1 = np.linalg.norm(vect1)\n",
    "    mag_vect2 = np.linalg.norm(vect2)\n",
    "    \n",
    "    return np.dot(vect1,vect2) / (mag_vect1 * mag_vect2)\n",
    "\n",
    "def list_most_similar_docs(model, vect):\n",
    "    for doc_id, cos_sim in model.docvecs.most_similar(vect, topn=30):\n",
    "        try:\n",
    "            resp = requests.get('http://localhost:9200/tmdb/movie/{}?_source=overview,title'.format(doc_id)).json()\n",
    "            print(resp['_source']['title'], cos_sim)\n",
    "        except e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to Load Preanalyzed Data\n",
      "Training\n",
      "training on 22055 docs\n",
      "Saving\n"
     ]
    }
   ],
   "source": [
    "from word2vec import prepare_model\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch()\n",
    "# window=10,negative=10,min_count=3\n",
    "modelep20 = prepare_model(es=es, window=15, negative=10, \n",
    "                          vector_size=300, min_count=5,\n",
    "                          epochs=20)\n",
    "\n",
    "#modelep10 = prepare_model(es=es, window=15, negative=10, \n",
    "#                          vector_size=300, min_count=5,\n",
    "#                          epochs=10)\n",
    "\n",
    "#print(\"Training epochs=100\")\n",
    "#modelep100 = prepare_model(es=es, window=5, negative=10, \n",
    "#                           vector_size=300, min_count=5,\n",
    "#                           epochs=100)\n",
    "\n",
    "model = modelep20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "rambo = model.docvecs['7555']\n",
    "star_wars = model.docvecs['11']\n",
    "clone_wars = model.docvecs['12180']\n",
    "empire_strikes_back = model.docvecs['1891']\n",
    "return_of_the_jedi = model.docvecs['1892']\n",
    "conan_the_destroyer = model.docvecs['9610']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('darth', 0.7670223712921143),\n",
       " ('skywalk', 0.7347890138626099),\n",
       " ('vader', 0.6643474102020264),\n",
       " ('galact', 0.6498984098434448),\n",
       " ('anakin', 0.6397547721862793),\n",
       " ('emperor', 0.626189649105072),\n",
       " ('galaxi', 0.6145325303077698),\n",
       " ('knight', 0.5965883731842041),\n",
       " ('obi', 0.5741980671882629),\n",
       " ('ruler', 0.5601556301116943),\n",
       " ('legion', 0.5379891395568848),\n",
       " ('sultan', 0.5364062786102295),\n",
       " ('brainiac', 0.5347437262535095),\n",
       " ('defeat', 0.5179133415222168),\n",
       " ('warrior', 0.5130146145820618),\n",
       " ('pharaoh', 0.5097701549530029),\n",
       " ('richelieu', 0.50380539894104),\n",
       " ('merlin', 0.5035779476165771),\n",
       " ('protector', 0.500783383846283),\n",
       " ('despot', 0.50030517578125)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar([\"jedi\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('darth', 0.7670223712921143),\n",
       " ('skywalk', 0.7347890138626099),\n",
       " ('vader', 0.6643474102020264),\n",
       " ('galact', 0.6498984098434448),\n",
       " ('anakin', 0.6397547721862793),\n",
       " ('emperor', 0.626189649105072),\n",
       " ('galaxi', 0.6145325303077698),\n",
       " ('knight', 0.5965883731842041),\n",
       " ('obi', 0.5741980671882629),\n",
       " ('ruler', 0.5601556301116943),\n",
       " ('legion', 0.5379891395568848),\n",
       " ('sultan', 0.5364062786102295),\n",
       " ('brainiac', 0.5347437262535095),\n",
       " ('defeat', 0.5179133415222168),\n",
       " ('warrior', 0.5130146145820618),\n",
       " ('pharaoh', 0.5097701549530029),\n",
       " ('richelieu', 0.50380539894104),\n",
       " ('merlin', 0.5035779476165771),\n",
       " ('protector', 0.500783383846283),\n",
       " ('despot', 0.50030517578125)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar([\"jedi\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'han_solo' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-8e461ee31cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"han_solo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'han_solo' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.wv.most_similar([\"han_solo\"], topn=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('han_solo', 0.46316754817962646),\n",
       " ('ottoman', 0.3639509677886963),\n",
       " ('skywalk', 0.34860068559646606),\n",
       " ('leaguer', 0.33654940128326416),\n",
       " ('droid', 0.3167843818664551),\n",
       " ('shackleton', 0.30565544962882996),\n",
       " ('oppressor', 0.3048733174800873),\n",
       " ('armageddon', 0.30078086256980896),\n",
       " ('ninja_turtl', 0.2923094630241394),\n",
       " ('entebb', 0.28573381900787354),\n",
       " ('concord', 0.2833603322505951),\n",
       " ('turk', 0.2757364511489868),\n",
       " ('manchu', 0.27319446206092834),\n",
       " ('hubbl', 0.2685926556587219),\n",
       " ('dirig', 0.26790666580200195),\n",
       " ('nemo', 0.26689231395721436),\n",
       " ('ruechang', 0.2664097547531128),\n",
       " ('everest', 0.26431891322135925),\n",
       " ('thrush', 0.2629425823688507),\n",
       " ('darth', 0.2584596276283264)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.wv.most_similar([star_wars], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rp import random_projection\n",
    "\n",
    "rp_vects = []\n",
    "for i in range(0,50):\n",
    "    vect, lhs, rhs = random_projection(model.docvecs.vectors_docs)\n",
    "    rp_vects.append(vect)\n",
    "    \n",
    "def rp_sim(rp_vects, vect1, vect2):\n",
    "    same_sign = 0\n",
    "    for rp_vect in rp_vects:\n",
    "        dp1 = np.dot(rp_vect, vect1)\n",
    "        dp2 = np.dot(rp_vect, vect2)\n",
    "        if dp1 > 0 and dp2 > 0:\n",
    "            same_sign += 1\n",
    "        elif dp1 < 0 and dp2 < 0:\n",
    "            same_sign += 1\n",
    "    return same_sign / len(rp_vects)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69055754"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(star_wars, return_of_the_jedi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61420316"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analyzed_docs import overview_text_no_stop\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "def get_movie_text(movie_id):\n",
    "    resp = requests.get(\"http://localhost:9200/tmdb/movie/%s?_source=overview\" % movie_id).json()\n",
    "    es = Elasticsearch()\n",
    "    return overview_text_no_stop(es, resp['_source']['overview'])\n",
    "\n",
    "\n",
    "def get_text_vectors(terms):\n",
    "    vects = []\n",
    "    for term in terms:\n",
    "        stopwords = [\"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\",\n",
    "            \"for\", \"if\", \"in\", \"into\", \"is\", \"it\",\n",
    "            \"no\", \"not\", \"of\", \"on\", \"or\", \"such\",\n",
    "            \"that\", \"the\", \"their\", \"then\", \"there\", \"these\",\n",
    "            \"they\", \"this\", \"to\", \"was\", \"will\", \"with\"]\n",
    "        if term in model.wv:\n",
    "            if term not in stopwords:\n",
    "                vects.append(model.wv[term])\n",
    "    return np.array(vects)\n",
    "            \n",
    "\n",
    "    \n",
    "sw_avg = np.average(get_text_vectors(get_movie_text(11)), axis=0)\n",
    "esb_avg = np.average(get_text_vectors(get_movie_text(1891)), axis=0)\n",
    "rj_avg = np.average(get_text_vectors(get_movie_text(1892)), axis=0)\n",
    "rb_avg = np.average(get_text_vectors(get_movie_text(7555)), axis=0)\n",
    "co_avg = np.average(get_text_vectors(get_movie_text(9610)), axis=0)\n",
    "cd_avg = np.average(get_text_vectors(get_movie_text(11977)), axis=0)\n",
    "\n",
    "cos(rb_avg, rj_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tournament', 0.5479854345321655),\n",
       " ('competit', 0.5235376358032227),\n",
       " ('prestigi', 0.5121024250984192),\n",
       " ('firm', 0.502556324005127),\n",
       " ('caddi', 0.5013620853424072),\n",
       " ('scholarship', 0.4951714277267456),\n",
       " ('contest', 0.49273645877838135),\n",
       " ('compet', 0.48250657320022583),\n",
       " ('colleg', 0.4787086844444275),\n",
       " ('coach', 0.4691489040851593),\n",
       " ('succe', 0.451945424079895),\n",
       " ('club', 0.44660183787345886),\n",
       " ('promot', 0.44326022267341614),\n",
       " ('competitor', 0.44222819805145264),\n",
       " ('he', 0.44177770614624023),\n",
       " ('posit', 0.44119346141815186),\n",
       " ('exam', 0.44059622287750244),\n",
       " ('job', 0.43727046251296997),\n",
       " ('instructor', 0.42816585302352905),\n",
       " ('school', 0.4090803265571594)]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar([cd_avg], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten Tall Men 0.44316595792770386\n",
      "Deathstalker 0.4228644371032715\n",
      "Family Guy Presents: It's a Trap! 0.40969473123550415\n",
      "Threads of Destiny 0.4064246714115143\n",
      "Star Wars: Episode III - Revenge of the Sith 0.4062676429748535\n",
      "Hercules Against the Mongols 0.38845205307006836\n",
      "Conan the Destroyer 0.3862627446651459\n",
      "The Three Musketeers 0.3849222660064697\n",
      "Yellowstone Kelly 0.3694799840450287\n",
      "Star Wars: Episode II - Attack of the Clones 0.36654961109161377\n",
      "Revolt of the Praetorians 0.3592129349708557\n",
      "The Swan Princess: Escape from Castle Mountain 0.35879823565483093\n",
      "Lady Bloodfight 0.35753387212753296\n",
      "Captain America: The Winter Soldier 0.356174111366272\n",
      "Seven Slaves Against the World 0.35602104663848877\n",
      "Jarhead 2: Field of Fire 0.3552103042602539\n",
      "The Divine Weapon 0.3544091582298279\n",
      "Dr. No 0.353972464799881\n",
      "Starship Apocalypse 0.3537600040435791\n",
      "Aquaman 0.3509889245033264\n",
      "Ninja 4: Siege 0.35021495819091797\n",
      "The Lives of a Bengal Lancer 0.34963685274124146\n",
      "The Saint 0.349540650844574\n",
      "The Three Stooges Meet Hercules 0.3482419550418854\n",
      "Kung Fu Killer 0.3479304909706116\n",
      "The 10th Kingdom 0.3429325819015503\n",
      "The Firefly 0.34232059121131897\n",
      "The Hobbit: The Battle of the Five Armies 0.3420221209526062\n",
      "SAGA - Curse of the Shadow 0.3418811559677124\n",
      "Carry On Cleo 0.34073567390441895\n"
     ]
    }
   ],
   "source": [
    "list_most_similar_docs(model, [sw_avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dissimilar\n",
    "list_most_similar_docs(model, vect=np.negative(star_wars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07022353"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(the_dinner_game, star_wars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06100053463596857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(vect, castle_in_the_sky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13079807"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(rambo, star_wars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_sim(rp_vects, star_wars, conan_the_destroyer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_sim(rp_vects, star_wars, empire_strikes_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_sim(rp_vects, star_wars, castle_in_the_sky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_sim(rp_vects, star_wars, rambo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_sim(rp_vects, star_wars, the_dinner_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__ignoreds',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__numpys',\n",
       " '__recursive_saveloads',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__scipys',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_input_data_sanity',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_epoch',\n",
       " '_do_train_job',\n",
       " '_get_job_params',\n",
       " '_get_offsets_and_start_doctags_for_corpusfile',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_specials',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_set_train_params',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_train_epoch_corpusfile',\n",
       " '_update_job_params',\n",
       " '_worker_loop',\n",
       " '_worker_loop_corpusfile',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'callbacks',\n",
       " 'cbow_mean',\n",
       " 'clear_sims',\n",
       " 'comment',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'corpus_total_words',\n",
       " 'cum_table',\n",
       " 'dbow',\n",
       " 'dbow_words',\n",
       " 'delete_temporary_training_data',\n",
       " 'dm',\n",
       " 'dm_concat',\n",
       " 'dm_tag_count',\n",
       " 'docvecs',\n",
       " 'doesnt_match',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'estimated_lookup_memory',\n",
       " 'evaluate_word_pairs',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'infer_vector',\n",
       " 'init_sims',\n",
       " 'iter',\n",
       " 'layer1_size',\n",
       " 'load',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'model_trimmed_post_training',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'n_similarity',\n",
       " 'negative',\n",
       " 'ns_exponent',\n",
       " 'random',\n",
       " 'reset_from',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'sg',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'syn0_lockf',\n",
       " 'syn1',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'trainables',\n",
       " 'vector_size',\n",
       " 'vocabulary',\n",
       " 'window',\n",
       " 'wmdistance',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
